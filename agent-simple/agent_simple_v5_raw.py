# agent_simple_v5_raw.py
# =========================================================
# v5 RAW ç‰ˆæœ¬å®šä½ï¼š
# - æ ¸å¿ƒæ€æƒ³ï¼šState = äº‹å®å¿«ç…§ï¼ˆimmutable é£æ ¼ï¼‰
# - Agent ä»ç„¶ç›´æ¥â€œç”Ÿæˆä¸‹ä¸€ä¸ª Stateâ€
# - Runtime è´Ÿè´£æ¨è¿›æ—¶é—´ï¼Œä½†ä¸åšçŠ¶æ€è§£é‡Š
# - Episode åªæ˜¯çŠ¶æ€è½¨è¿¹çš„ç®€å•è®°å½•
#
# ğŸ‘‰ è¿™æ˜¯ä»ã€ŒçŠ¶æ€å³è¡Œä¸ºç»“æœã€èµ°å‘
#    ã€ŒçŠ¶æ€ / å†³ç­– / Runtime è§£è€¦ã€ä¹‹å‰çš„å…³é”®è¿‡æ¸¡ç‰ˆæœ¬
# =========================================================

import json
from copy import deepcopy
from dataclasses import dataclass, field, asdict
from datetime import datetime
from typing import List, Optional


# -------------------------
# Agent Stateï¼ˆäº‹å®å¿«ç…§ï¼‰
# -------------------------
@dataclass()
class AgentState:
    agent_id: str
    step: int = 0
    reward: float = 0.0
    memory: List[str] = field(default_factory=list)
    last_action: Optional[str] = None
    last_observation: Optional[str] = None
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())

    def snapshot(self) -> "AgentState":
        """
        è¿”å›å½“å‰çŠ¶æ€çš„æ·±æ‹·è´
        æ ¸å¿ƒè¯­ä¹‰ï¼šState æ˜¯ä¸å¯å˜çš„ï¼Œæ¯ä¸€æ¬¡å˜åŒ–éƒ½ä¼šç”Ÿæˆæ–° State
        """
        return deepcopy(self)

    # ---- ä»¥ä¸‹æ–¹æ³•éƒ½æ˜¯â€œçŠ¶æ€æ¼”åŒ– APIâ€ ----
    # æ¯ä¸ªæ–¹æ³•éƒ½ä¼šè¿”å›ä¸€ä¸ªå…¨æ–°çš„ AgentState

    def add_memory(self, entry: str) -> "AgentState":
        new_state = self.snapshot()
        new_state.memory.append(entry)
        return new_state

    def set_action(self, action: str) -> "AgentState":
        new_state = self.snapshot()
        new_state.last_action = action
        return new_state

    def set_observation(self, observation: str) -> "AgentState":
        new_state = self.snapshot()
        new_state.last_observation = observation
        return new_state

    def add_reward(self, delta: float) -> "AgentState":
        new_state = self.snapshot()
        new_state.reward += delta
        return new_state

    def next_step(self) -> "AgentState":
        """
        æ—¶é—´æ¨è¿›ï¼š
        step çš„é€’å¢ä¾ç„¶å‘ç”Ÿåœ¨ State å†…éƒ¨
        ï¼ˆè¿™åœ¨ v6 ä¼šè¢« Runtime æ¥ç®¡ï¼‰
        """
        new_state = self.snapshot()
        new_state.step += 1
        return new_state

    # ---- åºåˆ—åŒ–ç›¸å…³ ----
    def to_dict(self):
        return asdict(self)

    def to_json(self) -> str:
        return json.dumps(self.to_dict(), ensure_ascii=False)

    @staticmethod
    def from_json(s: str) -> "AgentState":
        data = json.loads(s)
        return AgentState(**data)

    def show(self):
        print(f"Step {self.step} | Reward: {self.reward}")
        print(f"Memory: {self.memory}")
        print(f"Last action: {self.last_action}")
        print(f"Last observation: {self.last_observation}")
        print("-" * 50)


# -------------------------
# Episode Stepï¼ˆçŠ¶æ€è½¨è¿¹èŠ‚ç‚¹ï¼‰
# -------------------------
@dataclass
class EpisodeStep:
    """
    v5 ä¸­ï¼š
    - EpisodeStep åªæ˜¯â€œçŠ¶æ€çš„è®°å½•â€
    - action / observation / reward ä»ç„¶ç›´æ¥æ¥è‡ª State
    """
    state: AgentState
    action: Optional[str] = None
    observation: Optional[str] = None
    reward: Optional[float] = None
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())


# -------------------------
# Episodeï¼ˆè½¨è¿¹ï¼‰
# -------------------------
@dataclass
class Episode:
    steps: List[EpisodeStep] = field(default_factory=list)

    def snapshot(self) -> "Episode":
        """Episode ä¹Ÿéµå¾ªä¸å¯å˜è®¾è®¡"""
        return deepcopy(self)

    def add_step(self, state: AgentState) -> "Episode":
        """
        è®°å½•æŸä¸€æ—¶åˆ»çš„ State
        """
        new_episode = self.snapshot()
        step_record = EpisodeStep(
            state=state,
            action=state.last_action,
            observation=state.last_observation,
            reward=state.reward
        )
        new_episode.steps.append(step_record)
        return new_episode

    def show(self):
        print("Episode trajectory:")
        for s in self.steps:
            print(
                f"Step {s.state.step} | "
                f"Reward: {s.reward} | "
                f"Action: {s.action} | "
                f"Observation: {s.observation}"
            )
        print("=" * 60)


# -------------------------
# Agentï¼ˆä»ç„¶ç›´æ¥â€œäº§å‡º Stateâ€ï¼‰
# -------------------------
@dataclass()
class SimpleAgent:
    """
    v5 çš„ Agent ä»ç„¶ï¼š
    - ç›´æ¥ä¿®æ”¹ / ç”Ÿæˆä¸‹ä¸€ä¸ª State
    - å°šæœªå¼•å…¥ Decision æ¦‚å¿µ
    """
    def act(self, state: AgentState) -> "AgentState":
        if "ç®±å­" in "".join(state.memory):
            return (
                state
                .add_memory("æ£€æŸ¥ç®±å­æ˜¯å¦æœ‰é‡‘å¸")
                .set_action("æ‰“å¼€ç®±å­")
                .add_reward(0.0)
                .next_step()
            )
        else:
            return state.next_step()


# -------------------------
# Runtimeï¼ˆæ‰§è¡Œé©±åŠ¨ï¼‰
# -------------------------
@dataclass()
class AgentRuntime:
    """
    v5 Runtime çš„èŒè´£ï¼š
    - é©±åŠ¨å¾ªç¯
    - è°ƒç”¨ agent.act
    - è®°å½• Episode
    """
    def run(self, agent: SimpleAgent, init_state: AgentState, steps=3) -> "Episode":
        state = init_state
        episode = Episode()

        for _ in range(steps):
            episode = episode.add_step(state)
            state = agent.act(state)

        return episode


# -------------------------
# ç¤ºä¾‹æ¼”ç¤º
# -------------------------
if __name__ == "__main__":
    state0 = AgentState(agent_id="agent-001")
    state0.show()

    state1 = (
        state0.add_memory("è§‚å¯Ÿåˆ°æˆ¿é—´å†…æœ‰ä¸€ä¸ªç®±å­")
        .set_action("æ‰“å¼€ç®±å­")
        .set_observation("ç®±å­é‡Œé¢æœ‰é‡‘å¸")
        .add_reward(5)
        .next_step()
    )
    state1.show()

    state2 = (
        state1.add_memory("è§‚å¯Ÿåˆ°ç®±å­é‡Œé¢æœ‰é‡‘å¸,æ—è¾¹5må†…æœ‰å”®è´§æœº")
        .set_action("å°†é‡‘å¸æŠ•å…¥å”®è´§æœº,ä¹°äº†ä¸€ç“¶å¯ä¹")
        .set_observation("å¯ä¹åˆ°æ‰‹")
        .add_reward(-3)
        .next_step()
    )
    state2.show()

    state3 = (
        state2.add_memory("å¯ä¹åˆ°æ‰‹,è¿˜æ˜¯å†°é•‡çš„")
        .set_action("å“å°å¯ä¹")
        .set_observation("å¯ä¹çœŸç¾å‘³")
        .next_step()
    )
    state3.show()

    episode = Episode()
    episode = episode.add_step(state0)
    episode = episode.add_step(state1)
    episode = episode.add_step(state2)
    episode = episode.add_step(state3)
    episode.show()

    agent = SimpleAgent()
    runtime = AgentRuntime()
    runtime.run(agent, state1, 3).show()
